{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimCLR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependency"
      ],
      "metadata": {
        "id": "8_Vjp4hfDzwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U albumentations                 \n",
        "!pip install -q opencv-python-headless==4.1.2.30   \n",
        "!pip install -q --upgrade --force-reinstall --no-deps kaggle\n",
        "!pip install -q  --upgrade wandb \n",
        "!pip install -q --upgrade timm"
      ],
      "metadata": {
        "id": "4znLNqUQDzwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6OglrS8DzwR"
      },
      "source": [
        "### configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PB2_ezK4DzwR"
      },
      "outputs": [],
      "source": [
        "NAME = \"Rifat\" #your name here\n",
        "PROJECT_NAME = \"SimCLR\"\n",
        "MODEL_TYPE = \"Unsupervised\"\n",
        "ARCHITECTURE_NAME = \"tf_efficientnet__b0\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Download Kaggle Dataset and Dataframe create**"
      ],
      "metadata": {
        "id": "NWduLqs6DzwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from imutils import paths\n",
        "from google.colab import files\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "y7uzzqNlDzwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "unS8ec3eDzwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Download and unzip**"
      ],
      "metadata": {
        "id": "86rp6JlIDzwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d trolukovich/apparel-images-dataset\n",
        "!mkdir dataset\n",
        "!unzip -q apparel-images-dataset.zip -d ./dataset"
      ],
      "metadata": {
        "id": "Kp1N6uC6DzwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataframe Create**"
      ],
      "metadata": {
        "id": "00yB3aWfDzwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imagePaths = sorted(list(paths.list_images(\"/content/dataset/\")))\n",
        "directory=\"/content/dataset/\"\n",
        "data = []\n",
        "labels = []\n",
        "for imagePath in imagePaths:\n",
        "\tl = label = imagePath.split(os.path.sep)[-2]\n",
        "\tlabels.append(l)\n",
        "\n",
        "df = pd.DataFrame(labels,columns=['labels'])\n",
        "df['labels'] = df['labels'].astype('category')\n",
        "\n",
        "inverse_mapping = list(df['labels'].cat.categories)"
      ],
      "metadata": {
        "id": "Q-HSgtKHDzwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataframe Shuffle and Split**"
      ],
      "metadata": {
        "id": "3ZW6rvdKDzwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = shuffle(pd.read_csv(\"/content/df_apparel_multiclass.csv\"))\n",
        "train_dataframe , test_dataframe = train_test_split(df,test_size = 0.02)\n",
        "print(len(train_dataframe))\n",
        "print(len(test_dataframe))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf8f5683-aa79-4fbe-dcbb-87f9ae92814d",
        "id": "BJlf0fBrDzwT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11157\n",
            "228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Useful imports**"
      ],
      "metadata": {
        "id": "1ftnaWSjDzwT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLueAT6hDzwU"
      },
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms as T\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18\n",
        "import timm,time\n",
        "import os\n",
        "from PIL import Image\n",
        "from collections import OrderedDict\n",
        "\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import wandb\n",
        "tsne = TSNE()\n",
        "# device is set to cuda if cuda is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variables**"
      ],
      "metadata": {
        "id": "7YH95hTDDzwU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2tVqzVnDzwU"
      },
      "source": [
        "# defining a mapping between class names and numbers\n",
        "\n",
        "losses_train = []\n",
        "num_epochs = 20\n",
        "tau = 0.05\n",
        "learning_rate = 0.001\n",
        "save_path_checkpoints= \"/content/model/ckpts\"\n",
        "os.makedirs(save_path_checkpoints, exist_ok=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Class**"
      ],
      "metadata": {
        "id": "ra15Mk0vDzwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset_alb(Dataset):\n",
        "    def __init__(self, dataframe,weak_transform,strong_transform,train=True):\n",
        "        self.dataframe = dataframe\n",
        "        self.weak_transform = weak_transform\n",
        "        self.strong_transform = strong_transform\n",
        "        self.train = train\n",
        "        self.all_image_names = self.dataframe[:]['ImagePath']\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.all_image_names)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = os.path.join(self.all_image_names.iloc[index])\n",
        "        image = cv2.imread(img_path)                                      # added for albumentations\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
        "        if  self.train:                 \n",
        "          sample = {'image1': self.weak_transform(image=image)[\"image\"],\n",
        "                    'image2': self.strong_transform(image=image)[\"image\"]}\n",
        "        else:            \n",
        "            sample = {'image': self.weak_transform(image=image)[\"image\"]}\n",
        "        return sample"
      ],
      "metadata": {
        "id": "Dyv-yNqlDzwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataloader and Transfrom**"
      ],
      "metadata": {
        "id": "6SRxeWIpDzwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fun_alb_transfrom():\n",
        "  strong_transform = A.Compose(\n",
        "    [\n",
        "        A.RandomResizedCrop(p=1.0, height=224, width=224, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=0),\n",
        "        A.HorizontalFlip(p=1.0),\n",
        "        A.ColorJitter (brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5,  p=1.0),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        "\n",
        "      \n",
        "  )\n",
        "\n",
        "  weak_transform = A.Compose(\n",
        "      [\n",
        "      A.Resize(p=1.0, height=224, width=224, interpolation=0),\n",
        "      A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "      ToTensorV2(),\n",
        "\n",
        "      ]\n",
        "  )\n",
        "\n",
        "\n",
        "  train_dataset = ImageDataset_alb(\n",
        "      train_dataframe,\n",
        "      weak_transform,\n",
        "      strong_transform,\n",
        "      train = True\n",
        "      \n",
        "  )\n",
        "\n",
        "  test_dataset = ImageDataset_alb(\n",
        "      test_dataframe,\n",
        "      weak_transform,\n",
        "      strong_transform,\n",
        "      train = False\n",
        "      \n",
        "  )\n",
        "  \n",
        "  dataloader_training_dataset = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "  dataloader_testing_dataset = DataLoader(test_dataset, batch_size=len(test_dataframe), shuffle=True, num_workers=2)\n",
        "  return dataloader_training_dataset,dataloader_testing_dataset\n",
        "\n",
        "\n",
        "dataloader_training_dataset,dataloader_testing_dataset = fun_alb_transfrom()"
      ],
      "metadata": {
        "id": "Ld0n_36mDzwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq1OJj0Fb7uV"
      },
      "source": [
        "**Wandb**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1M97VqEEMzf_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a3c863e-2c6c-4f2d-915c-f0b010eda35c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "!wandb login "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3YKEACgfYzp"
      },
      "outputs": [],
      "source": [
        "class WandbLogger():\n",
        "    \"\"\"\n",
        "    This custom callback is used for logging training metrics to wandb for monitoring.\n",
        "    \n",
        "    \"\"\"\n",
        "    def __init__(self,project,entity,name,id,config,resume = \"allow\",):\n",
        "      self.project = project\n",
        "      self.entity = entity\n",
        "      self.name = name\n",
        "      self.id = id\n",
        "      self.config = config\n",
        "      self.resume = resume\n",
        "      wandb.init(project = self.project,entity = self.entity,\n",
        "                 name = self.name,id = self.id, \n",
        "                 config = self.config,resume = self.resume)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6pk20PrcAPR"
      },
      "outputs": [],
      "source": [
        "project= PROJECT_NAME\n",
        "entity=\"rakib1521\"\n",
        "\n",
        "\n",
        "name = f\"{PROJECT_NAME}_{ARCHITECTURE_NAME}\" #same name for multiple run is allowed but same id is not allowed\n",
        "id = f\"{PROJECT_NAME}_{ARCHITECTURE_NAME}\"\n",
        "\n",
        "wandb_config = {\"network\":ARCHITECTURE_NAME,\n",
        "                \"epoch\":num_epochs,\n",
        "                \"tau\": tau,\n",
        "                \"learning_rate\": learning_rate,\n",
        "                }\n",
        "wandb_logger = WandbLogger(project,entity,name,id,wandb_config)    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Define"
      ],
      "metadata": {
        "id": "qPgVMZhjDzwV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8AHa2fFDzwV"
      },
      "source": [
        "# defining our deep learning architecture\n",
        "#model = resnet18(pretrained=False)\n",
        "\"\"\"\n",
        "model = timm.create_model(\"tf_efficientnet_b0\")\n",
        "\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "    ('fc1', nn.Linear(model.fc.in_features, 256)),\n",
        "    ('added_relu1', nn.ReLU(inplace=True)),\n",
        "    ('fc2', nn.Linear(256, 128)),\n",
        "    ('added_relu2', nn.ReLU(inplace=True)),\n",
        "    ('fc3', nn.Linear(128, 64))\n",
        "]))\n",
        "\n",
        "model.fc = classifier\n",
        "\n",
        "# moving the resnet architecture to device\n",
        "model.to(device)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining our deep learning architecture\n",
        "#model = resnet18(pretrained=False)\n",
        "model = timm.create_model(\"tf_efficientnet_b0\")\n",
        "\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "    ('fc1', nn.Linear(model.classifier.in_features, 256)),\n",
        "    ('added_relu1', nn.ReLU(inplace=True)),\n",
        "    ('fc2', nn.Linear(256, 128)),\n",
        "    ('added_relu2', nn.ReLU(inplace=True)),\n",
        "    ('fc3', nn.Linear(128, 64))\n",
        "]))\n",
        "\n",
        "model.classifier = classifier\n",
        "\n",
        "# moving the resnet architecture to device\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "cpRRI3F8R10g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function"
      ],
      "metadata": {
        "id": "h7j3B7iGDzwV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8Dlv1MIDzwW"
      },
      "source": [
        "# Code for NT-Xent Loss function\n",
        "def loss_function(a, b):\n",
        "    a_norm = torch.norm(a, dim=1).reshape(-1, 1)\n",
        "    a_cap = torch.div(a, a_norm)\n",
        "    b_norm = torch.norm(b, dim=1).reshape(-1, 1)\n",
        "    b_cap = torch.div(b, b_norm)\n",
        "    a_cap_b_cap = torch.cat([a_cap, b_cap], dim=0)\n",
        "    a_cap_b_cap_transpose = torch.t(a_cap_b_cap)\n",
        "    b_cap_a_cap = torch.cat([b_cap, a_cap], dim=0)\n",
        "    sim = torch.mm(a_cap_b_cap, a_cap_b_cap_transpose)\n",
        "    sim_by_tau = torch.div(sim, tau)\n",
        "    exp_sim_by_tau = torch.exp(sim_by_tau)\n",
        "    sum_of_rows = torch.sum(exp_sim_by_tau, dim=1)\n",
        "    exp_sim_by_tau_diag = torch.diag(exp_sim_by_tau)\n",
        "    numerators = torch.exp(torch.div(torch.nn.CosineSimilarity()(a_cap_b_cap, b_cap_a_cap), tau))\n",
        "    denominators = sum_of_rows - exp_sim_by_tau_diag\n",
        "    num_by_den = torch.div(numerators, denominators)\n",
        "    neglog_num_by_den = -torch.log(num_by_den)\n",
        "    return torch.mean(neglog_num_by_den)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training "
      ],
      "metadata": {
        "id": "oLjXdKMPDzwW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bJ_TgMHDzwW"
      },
      "source": [
        "# using SGD optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "# Note that this training is unsupervised, it uses the NT-Xent Loss function\n",
        "\n",
        "TRAINING = True\n",
        "\n",
        "def get_mean_of_list(L):\n",
        "    return sum(L) / len(L)\n",
        "\n",
        "if TRAINING:\n",
        "    # get resnet in train mode\n",
        "    model.train()\n",
        "\n",
        "    # run a for loop for num_epochs\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # a list to store losses for each epoch\n",
        "        epoch_losses_train = []\n",
        "\n",
        "        # run a for loop for each batch\n",
        "        for (_, sample_batched) in enumerate(dataloader_training_dataset):\n",
        "            \n",
        "            # zero out grads\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # retrieve x1 and x2 the two image batches\n",
        "            x1 = sample_batched['image1']\n",
        "            x2 = sample_batched['image2']\n",
        "\n",
        "            # move them to the device\n",
        "            x1 = x1.to(device)\n",
        "            x2 = x2.to(device)\n",
        "\n",
        "            # get their outputs\n",
        "            y1 = model(x1)\n",
        "            y2 = model(x2)\n",
        "\n",
        "            #print(type(y1))\n",
        "            #print(type(y2))\n",
        "\n",
        "            # get loss value\n",
        "            loss = loss_function(y1, y2)\n",
        "            \n",
        "            # put that loss value in the epoch losses list\n",
        "            epoch_losses_train.append(loss.cpu().data.item())\n",
        "\n",
        "            # perform backprop on loss value to get gradient values\n",
        "            loss.backward()\n",
        "\n",
        "            # run the optimizer\n",
        "            optimizer.step()\n",
        "\n",
        "        # append mean of epoch losses to losses_train, essentially this will reflect mean batch loss\n",
        "        losses_train.append(get_mean_of_list(epoch_losses_train))\n",
        "        print(\"Epoch-{} Loss-{}\".format(epoch+1,get_mean_of_list(epoch_losses_train)))\n",
        "\n",
        "\n",
        "\n",
        "        wandb.log({ \"train_loss\": get_mean_of_list(epoch_losses_train),\n",
        "                })   \n",
        "        \n",
        "        \n",
        "\n",
        "        filepath=f\"{save_path_checkpoints}/{PROJECT_NAME}_{MODEL_TYPE}-{ARCHITECTURE_NAME}-{epoch+1}_loss-{get_mean_of_list(epoch_losses_train)}.pt\"    \n",
        "        checkpoint= {\n",
        "                      \"epoch\" : epoch+1 ,\n",
        "                      \"model_weight\" : model.state_dict(),\n",
        "                      \"optimizer_state\" : optimizer.state_dict()\n",
        "                      }\n",
        "        torch.save(checkpoint,filepath)\n",
        "        print(\"{} saved\".format(filepath))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOSS**"
      ],
      "metadata": {
        "id": "EHAY-qVuDzwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training losses Graph and save it\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "sns.set_style('darkgrid')\n",
        "plt.plot(losses_train)\n",
        "plt.legend(['Training Losses'])\n",
        "plt.savefig('losses.png')\n",
        "#plt.close()"
      ],
      "metadata": {
        "id": "9ySzRKjSDzwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "hAKRZfXgDzwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(inverse_mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZHR3xeOeaN-",
        "outputId": "7c08c4f9-9431-45eb-bbd2-488afea18583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a function used to plot t-SNE visualizations\n",
        "def plot_vecs_n_labels(v,labels,fname):\n",
        "    fig = plt.figure(figsize = (10, 10))\n",
        "    plt.axis('off')\n",
        "    sns.set_style(\"darkgrid\")\n",
        "    sns.scatterplot(v[:,0], v[:,1], hue=labels, legend='full', palette=sns.color_palette(\"bright\", len(inverse_mapping)))\n",
        "    plt.legend(inverse_mapping)\n",
        "    plt.savefig(fname)\n",
        "    wandb.log({\"Test\":wandb.Image(fname)})\n",
        "    #plt.close()\n",
        "\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "KJzbjqpTDzwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TSNE visualizations of test dataset\n",
        "for (_, sample_batched) in enumerate(dataloader_testing_dataset):\n",
        "     x = sample_batched['image']\n",
        "     x = x.to(device)\n",
        "     y = model(x)\n",
        "     y_tsne = tsne.fit_transform(y.cpu().data)\n",
        "     labels = list(test_dataframe['label'])\n",
        "     plot_vecs_n_labels(y_tsne,labels,'tsne_test_last_layer.png')\n"
      ],
      "metadata": {
        "id": "PwUQrGH3DzwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "nKdhH6CQfheN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5jVeJs9zeuNe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}